{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6GOjs8Axh3j"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "\n",
        "def load_pdf(pdf_file_path):\n",
        "    contents = []\n",
        "    doc = fitz.open(pdf_file_path)\n",
        "\n",
        "    for page in doc:\n",
        "        content = page.get_text()\n",
        "        contents.append(\"\\n\" + content)\n",
        "\n",
        "    return \"\\n\".join(contents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = load_pdf(\"C:/Users/gaurav/Downloads/resume.pdf\")"
      ],
      "metadata": {
        "id": "HQ9KVTi9xuzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_documents(text, chunk_size, overlap):\n",
        "\n",
        "\n",
        "\n",
        "    split_lists = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + chunk_size, len(text))\n",
        "        split_lists.append(text[start:end])\n",
        "        start += chunk_size - overlap\n",
        "\n",
        "    return split_lists"
      ],
      "metadata": {
        "id": "rsgD7Aqexzp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_documents(docs, 500, 50)"
      ],
      "metadata": {
        "id": "Gseg5z0mx8zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Torch save vectorstore -> Compute embeddings for document, Embedding Dict, Save Dict as Torch file\n",
        "\n",
        "def store_embeddings_as_dict(embeddings_list, text_list):\n",
        "    embeddings_dict = {text: embedding for text, embedding in zip(text_list, embeddings_list)}\n",
        "    return embeddings_dict\n",
        "\n",
        "def save_embeddings_to_pt(embeddings_dict, filename):\n",
        "    torch.save(embeddings_dict, filename)\n",
        "\n",
        "def create_vectorstore(embed_model, chunks):\n",
        "    chunk_embeddings = []\n",
        "    embedder = SentenceTransformer(embed_model)\n",
        "    for chunk in tqdm(chunks, desc=\"TestCases Embeddings...\"):\n",
        "        chunk_embedding = embedder.encode(chunk, convert_to_tensor=True).to(\"cpu\")\n",
        "        chunk_embeddings.append(chunk_embedding)\n",
        "    embeddings_dict = store_embeddings_as_dict(chunk_embeddings, chunks)\n",
        "    save_embeddings_to_pt(embeddings_dict, \"embeddings.pt\")"
      ],
      "metadata": {
        "id": "AlIvRmPXx-5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_vectorstore(\"sentence-transformers/all-MiniLM-L6-v2\", chunks)"
      ],
      "metadata": {
        "id": "bjcHe0SOy0up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util\n",
        "\n",
        "def retrieve_relevant_docs(embed_model, embeddings_path, query, top_k):\n",
        "    embedder = SentenceTransformer(embed_model)\n",
        "    embeddings_dict = torch.load(embeddings_path)\n",
        "    chunks = list(embeddings_dict.keys())\n",
        "    query_encoded = embedder.encode(query, convert_to_tensor=True)\n",
        "    top_k = min(top_k, len(embeddings_dict))\n",
        "    scores = []\n",
        "    for chunk in tqdm(chunks, desc=\"Computing Similarity...\"):\n",
        "        cos_score = util.cos_sim(query_encoded, embeddings_dict[chunk])[0]\n",
        "        scores.append(cos_score)\n",
        "    scores = torch.Tensor(scores)\n",
        "    top_k_chunk_indices = torch.topk(scores, k=top_k).indices.tolist()\n",
        "    top_k_chunks =[chunks[i] for i in top_k_chunk_indices]\n",
        "    return top_k_chunks"
      ],
      "metadata": {
        "id": "FGOT5CV0y2Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_docs = retrieve_relevant_docs(\"sentence-transformers/all-MiniLM-L6-v2\", \"embeddings.pt\", \"What are the skills specified\", 3)"
      ],
      "metadata": {
        "id": "jniIgZBtzBkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stuff_docs(relevant_chunks):\n",
        "    relevant_chunks = [f\"Document{i}: {value}\\n\\n\" for i, value in enumerate(relevant_chunks, start=1)]\n",
        "    stuffed_chunk = \"\".join(relevant_chunks)\n",
        "    return stuffed_chunk"
      ],
      "metadata": {
        "id": "xSD3gUyPz95K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stuffed_doc = stuff_docs(top_k_docs)"
      ],
      "metadata": {
        "id": "ZSObjKsZ0AC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Answer the question based on the given context alone.\n",
        "context: {context}\n",
        "question: {question}\n",
        "answer:\"\"\"\n"
      ],
      "metadata": {
        "id": "zzctOnyL0B5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "def qa(llm_name, context, question):\n",
        "    llm_inp = prompt.format(context=context, question=question)\n",
        "    client = Groq(api_key=\"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\")\n",
        "    chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": llm_inp,\n",
        "        }\n",
        "    ],\n",
        "    model=llm_name\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "wIfPYruX0GVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa(\"llama3-70b-8192\", top_k_docs, \"What are the skills specified\")"
      ],
      "metadata": {
        "id": "wFyF_Rzv0QTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}